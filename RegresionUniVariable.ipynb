{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3040cbea-78d9-4df0-9b17-010e01da8d20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4505664-a82b-4833-a28d-5ccd960b2f75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = np.load(\"proyecto_training_data.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1114ee-579d-44d7-b71f-e44616f3f2ad",
   "metadata": {},
   "source": [
    "#### 2. Usando sclicing con NumPy separar los datos en 2 datasets: entrenamiento(80 %) y validación y pruebas(20 %)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5108415-3c85-4af0-8521-0d6fca19ec70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Obtenemos un entero que nos indica en que posición del array podemos obtener el 80%\n",
    "sliceIndex = int(dataset.shape[0] * 0.8)\n",
    "\n",
    "# Modifica el orden de las filas\n",
    "np.random.shuffle(dataset)\n",
    "\n",
    "# Seleccionamos el 80% para el entrenamiento\n",
    "dataset_entrenamiento = dataset[:sliceIndex]\n",
    "\n",
    "# Seleccionamos el 20% para la validación\n",
    "dataset_validacion = dataset[sliceIndex:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1065bb-9461-4e53-91ec-7652aa400b82",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 3. Análisis exploratorio de datos: Para cada variable en el dataset calcular((usando numpy o pandas):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cfc0c4-064e-43ce-b9bc-185fafab8e70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "columnas = ['SalePrice', 'OverallQual', '1stFlrSF', 'TotRmsAbvGrd', 'YearBuilt', 'LotFrontage']\n",
    "\n",
    "dfEntrenamiento = pd.DataFrame(dataset_entrenamiento, columns=columnas)\n",
    "\n",
    "columnas = ['Media', 'Minimo', 'Maximo', 'ValorPeak', 'DesviacionEstandar']\n",
    "\n",
    "dfAnalisis = pd.DataFrame(columns=columnas)\n",
    "\n",
    "dfAnalisis['Media'] = dfEntrenamiento.mean()\n",
    "dfAnalisis['Minimo'] = dfEntrenamiento.min()\n",
    "dfAnalisis['Maximo'] = dfEntrenamiento.max()\n",
    "dfAnalisis['ValorPeak'] = dfAnalisis['Maximo'] - dfAnalisis['Minimo']\n",
    "dfAnalisis['DesviacionEstandar'] = dfEntrenamiento.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32436a48-3078-47e4-bf1b-bd5f8e9dcc47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfAnalisis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7f543a-a0be-4ab2-ba1f-8ef4537db6e1",
   "metadata": {},
   "source": [
    "#### 4. Para cada variable en el dataset usar seaborn para graficar un histograma de la variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ad0ec2-c927-4a7b-a5c1-ec1704d5b39a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54288ab4-3e5b-4cc1-ad5a-71daaebd1afd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for col in dfEntrenamiento.columns:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.histplot(dfEntrenamiento[col], kde=True)\n",
    "    plt.title(f'Histograma de {col}', fontsize=16)\n",
    "    \n",
    "    plt.xlabel(col, fontsize=14)\n",
    "    plt.ylabel('Frecuencia', fontsize=14)\n",
    "\n",
    "    plt.axvline(dfAnalisis.loc[col, 'Media'], color='red', linestyle='--', label='Media')\n",
    "    plt.axvline(dfAnalisis.loc[col, 'Maximo'], color='green', linestyle='--', label='Máximo')\n",
    "    plt.axvline(dfAnalisis.loc[col, 'Minimo'], color='blue', linestyle='--', label='Mínimo')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aabc9ce-bfab-4107-8881-5c72eda07b48",
   "metadata": {},
   "source": [
    "#### 5. Para cada variable independiente x:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c20ce0-2782-4209-9b37-9300f51a9f06",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Calcular el coeficiente de correlación entre x y y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0db4f85-beb6-43c3-8ab1-3d91225b9b5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfCorrelacionVariables = dfEntrenamiento.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e7a53e-33d9-4a86-bd7a-ca5f8b52f3e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfCorrelacionVariables.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4ac973-3783-493e-be2a-09091ffa1a0d",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Graficar x vs y(scatterplot) usando matplotlib.\n",
    "##### Colocar el coeficiente de correlación y colocarlo como parte del título de la gráfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c16c44-2fb9-4b0b-858c-a9eaa8dfc32e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SalePrice es la variable Y, por lo que se excluye de las X.\n",
    "variablesX = ['OverallQual', '1stFlrSF', 'TotRmsAbvGrd', 'YearBuilt', 'LotFrontage']\n",
    "variableY = 'SalePrice'\n",
    "\n",
    "for variableX in variablesX:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.scatterplot(x=variableX, y=variableY, data=dfEntrenamiento)\n",
    "    coeficiente = dfCorrelacionVariables.loc[[variableX], [variableY]].iloc[0,0]\n",
    "    plt.title(f\"{variableX} - {variableY} - {coeficiente}\", fontsize=16)\n",
    "    plt.xlabel(variableX, fontsize=14)\n",
    "    plt.ylabel(variableY, fontsize=14)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f2f828-686a-4218-924b-86262cb015b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Basado en la gráfica y el coeficiente de correlación de cada par x,y elegir las 2 variables con más potencial predictivo es decir las 2 variables que presentan mayor correlación entre dicha variable y la variable dependiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309489ac-268a-4af9-8f74-ee6bc66fe93f",
   "metadata": {},
   "source": [
    "##### Segun los diagramas y el dataframe de correlacion de variables, las variables que presentan una mayor correlacion son:\n",
    "##### 1. X (OverallQual) => Y (SalePrice)\n",
    "##### 2. X (1stFlrSF) => Y (SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87be383e-cb70-4928-81b9-b4ea77fec0cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfCorrelacionVariables.loc[['OverallQual', '1stFlrSF'], ['SalePrice']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42d926d-6f5d-41ac-b452-8e0bcf732320",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 6. Crear una función para entrenar un modelo de regresión lineal de una variable y = β0 + β1 ∗ x.\n",
    "##### La función recibe como argumentos:\n",
    "##### 6.1 Vector con la variable independiente x,\n",
    "##### 6.2 Vector con la variable dependiente y,\n",
    "##### 6.3 un entero epochs que indica por cuantas iteraciones entrenar el modelo.\n",
    "##### 6.4 un entero imprimir error cada, que nos indica cada cuantas iteraciones queremos imprimir a través de print: el número de iteración, el error del modelo en esa iteración, si imprimir error cada = 10, se despliega en pantalla el error en las iteraciones: 10,20,30,40,50.\n",
    "##### 6.5 escalar α(learning rate): es usado como parte de la expresión matemática para actualizar en cada iteración los parámetros del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9e2cfa-9f88-4398-86dc-4de34b11c1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b78a4c6-0fd1-401e-bd3c-41e995ae7ac8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Regresion:\n",
    "    #def __init__(self):\n",
    "\n",
    "    def calcular_gradiente(self, x, y, epochs, imprimir_error, learning_rate = 0.0001):\n",
    "        \n",
    "        # Crear una matriz de 2 columnas, la primera columna corresponde al vector de datos x \n",
    "        # y la segunda columna de la matriz para todas las filas es igual a 1.\n",
    "        observaciones = np.column_stack((x, np.ones_like(x)))\n",
    "        \n",
    "        # Inicializar los parámetros del modelo en un vector β0 y β1, esto es equivalente a empezar el proceso con una recta inicial \n",
    "        # la cual en cada iteración actualizaremos hasta encontrar una que aproxime de buena manera los datos x, y.\n",
    "        parametros = np.array([0.01, 0.1])\n",
    "        \n",
    "        n = len(x)\n",
    "        historial_parametros = {}\n",
    "        historial_error = {}\n",
    "        \n",
    "        # iterar las epocas\n",
    "        for i in range(epochs):\n",
    "            \n",
    "            # Calcular y (prediccioón o estimación) para todas las observaciones de manera simultánea(vectorizada) \n",
    "            # utilizando el modelo correspondiente a la iteración(es decir , los valores de β0 y β1,): \n",
    "            # esto produce un vector y con el mismo número de elementos que y.\n",
    "            # y = β0 + β1 * x.\n",
    "            #y_estimacion =  parametros[0] + (parametros[1] * x)\n",
    "            y_estimacion = np.dot(observaciones, parametros)\n",
    "            \n",
    "            # Calcular el error o costo usando\n",
    "            error_actual = np.mean((y - y_estimacion) ** 2)\n",
    "            \n",
    "            # Calcular el gradiente del error respecto de cada parámetro\n",
    "            # Realizar un solo cálculo cuyo resultado es un vector\n",
    "            gradientes = np.dot(observaciones.T, y_estimacion - y) / n\n",
    "            parametros -= learning_rate * gradientes \n",
    "\n",
    "            historial_parametros[i] = parametros\n",
    "            historial_error[i] = error_actual\n",
    "            \n",
    "            i += 1\n",
    "            mostrar_error = i % imprimir_error\n",
    "\n",
    "            # Muestra el error cada intervalo especificado en el parametro imprimir_error\n",
    "            if mostrar_error == 0:\n",
    "                print(f\"Iteration No. {i}: Error {error_actual}, Parametros (0,1) {parametros[0]}, {parametros[1]}\")\n",
    "                #print(f\"Iteration No. {i}: Error {error_actual}\")\n",
    "                \n",
    "        return historial_parametros, historial_error\n",
    "    \n",
    "    def grafica_historial_error(self, historial_errores):\n",
    "        iteraciones = list(historial_errores.keys())\n",
    "        errores = list(historial_errores.values())\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(iteraciones, errores, marker='o', color='blue')\n",
    "        plt.title('Historial de error por iteración')\n",
    "        plt.xlabel('Número de iteración')\n",
    "        plt.ylabel('Error')\n",
    "        #plt.grid(True)\n",
    "        plt.show()\n",
    "            \n",
    "    def graficar_historial_modelo(self, historial_modelos, n, x, y):\n",
    "        # Graficar el modelo para cada iteración a graficar\n",
    "        obs = np.column_stack((x, np.ones_like(x)))\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(x, y, color='blue', label='Entrenamiento manual')\n",
    "        \n",
    "        for iteracion, parametros in historial_modelos.items():\n",
    "            if iteracion % n == 0:\n",
    "                y_pred = np.dot(obs, parametros) #parametros[0] + parametros[1] * x\n",
    "                plt.plot(x, y_pred, color='red', label=f'Iteración {iteracion}')\n",
    "        \n",
    "        plt.title('Evolución del modelo entrenado en el tiempo')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "                \n",
    "                \n",
    "    def sklearn_calcular_gradiente(self, X, Y, x_label):\n",
    "        historial_parametros = {}\n",
    "        historial_error = {}\n",
    "        \n",
    "        linear_regresion = LinearRegression()\n",
    "        linear_regresion.fit(X.reshape(-1, 1), Y)\n",
    "\n",
    "        y_pred = linear_regresion.predict(X.reshape(-1, 1))\n",
    "\n",
    "        error = np.mean((Y - y_pred)**2)\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.scatter(X, Y, color='blue', label='Entrenamiento sklearn')\n",
    "        plt.plot(X, y_pred, color='red', label='Predicción')\n",
    "        plt.title(f'{x_label} vs SalePrice')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeeecd2d-675b-4f34-ad36-8ab8976a6671",
   "metadata": {},
   "source": [
    "#### Entrenando la variable 1 donde Y es SalePrice y X es OverallQual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "id": "243a5ad9-454d-44d5-a8ef-483aa8507dbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regresion = Regresion()\n",
    "X1 = dataset_entrenamiento[:,1]\n",
    "Y = dataset_entrenamiento[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "id": "3586bd70-1b9a-41b7-95bf-7671a632d2ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No. 4000: Error 2340942103.7913876, Parametros (0,1) 43613.02549882527, -84803.90996934645\n",
      "Iteration No. 8000: Error 2328503556.4496894, Parametros (0,1) 45769.061833581014, -98596.86025508425\n"
     ]
    }
   ],
   "source": [
    "historial_parametros, historial_error = regresion.calcular_gradiente(X1, Y, 8000, 4000, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd5fb2b-62db-4305-bd78-d33cb993f82c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regresion.grafica_historial_error(historial_error)\n",
    "regresion.graficar_historial_modelo(historial_parametros, 4000, X1, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f638f9-8b74-4485-a7c2-268ba9e4d34d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Entrenando la variable 2 donde Y es SalePrice y X es 1stFlrSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1031,
   "id": "e54fa855-5d44-424a-ae37-6fda51cb1f65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 691.],\n",
       "       [1779.],\n",
       "       [ 884.],\n",
       "       ...,\n",
       "       [ 774.],\n",
       "       [ 976.],\n",
       "       [1422.]])"
      ]
     },
     "execution_count": 1031,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regresion = Regresion()\n",
    "X2 = dataset_entrenamiento[:,2]\n",
    "Y = dataset_entrenamiento[:,0]\n",
    "\n",
    "X2.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "id": "5630f253-1418-4d00-9564-9133bb32985d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No. 10: Error 5947341611.810787, Parametros (0,1) 122.30194927038133, 0.19830584844761476\n"
     ]
    }
   ],
   "source": [
    "historial_parametros, historial_error = regresion.calcular_gradiente(X2, Y, 13, 10, 0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb58799-9329-46cf-8cf9-66ac10d9f1d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regresion.grafica_historial_error(historial_error)\n",
    "regresion.graficar_historial_modelo(historial_parametros, 4, X2, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a127bb47-c459-4fcd-bcc0-27ec1c29dd64",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Para cada una de las variables utilizar Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab653de-886a-4c2c-9df2-b7bd8b839cc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "regresion.sklearn_calcular_gradiente(X1, Y, 'OverallQual')\n",
    "regresion.sklearn_calcular_gradiente(X2, Y, '1stFlrSF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb933242-991b-45f4-9a25-7faa707ef77e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
